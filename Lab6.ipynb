{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trishul32/BIS_LAB/blob/main/Lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# ----------------------------------------\n",
        "# Objective Function: Rastrigin (nonlinear)\n",
        "# ----------------------------------------\n",
        "def rastrigin(X):\n",
        "    A = 10\n",
        "    return A * len(X) + np.sum(X**2 - A * np.cos(2 * np.pi * X))\n",
        "\n",
        "# ----------------------------------------\n",
        "# Grey Wolf Optimizer (Vectorized & Efficient)\n",
        "# ----------------------------------------\n",
        "def GWO(obj_func, dim, bounds, n_wolves=30, max_iter=500):\n",
        "    lb, ub = np.array(bounds[0]), np.array(bounds[1])\n",
        "\n",
        "    # Step 1: Initialize wolves randomly\n",
        "    wolves = np.random.uniform(lb, ub, (n_wolves, dim))\n",
        "    alpha, beta, delta = np.zeros(dim), np.zeros(dim), np.zeros(dim)\n",
        "    alpha_score, beta_score, delta_score = float('inf'), float('inf'), float('inf')\n",
        "\n",
        "    convergence_curve = []\n",
        "\n",
        "    # Start optimization\n",
        "    start_time = time.time()\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        # Step 2: Evaluate fitness for all wolves\n",
        "        fitness = np.apply_along_axis(obj_func, 1, wolves)\n",
        "\n",
        "        # Step 3: Update alpha, beta, delta wolves\n",
        "        for i in range(n_wolves):\n",
        "            if fitness[i] < alpha_score:\n",
        "                alpha_score, alpha = fitness[i], wolves[i].copy()\n",
        "            elif fitness[i] < beta_score:\n",
        "                beta_score, beta = fitness[i], wolves[i].copy()\n",
        "            elif fitness[i] < delta_score:\n",
        "                delta_score, delta = fitness[i], wolves[i].copy()\n",
        "\n",
        "        # Step 4: Update positions\n",
        "        a = 2 - 2 * (t / max_iter)  # linearly decreases from 2 to 0\n",
        "\n",
        "        for i in range(n_wolves):\n",
        "            r1, r2 = np.random.rand(dim), np.random.rand(dim)\n",
        "            A1, C1 = 2 * a * r1 - a, 2 * r2\n",
        "            D_alpha = np.abs(C1 * alpha - wolves[i])\n",
        "            X1 = alpha - A1 * D_alpha\n",
        "\n",
        "            r1, r2 = np.random.rand(dim), np.random.rand(dim)\n",
        "            A2, C2 = 2 * a * r1 - a, 2 * r2\n",
        "            D_beta = np.abs(C2 * beta - wolves[i])\n",
        "            X2 = beta - A2 * D_beta\n",
        "\n",
        "            r1, r2 = np.random.rand(dim), np.random.rand(dim)\n",
        "            A3, C3 = 2 * a * r1 - a, 2 * r2\n",
        "            D_delta = np.abs(C3 * delta - wolves[i])\n",
        "            X3 = delta - A3 * D_delta\n",
        "\n",
        "            # Update position\n",
        "            wolves[i] = (X1 + X2 + X3) / 3\n",
        "\n",
        "        # Step 5: Apply boundary limits\n",
        "        wolves = np.clip(wolves, lb, ub)\n",
        "\n",
        "        # Store best score\n",
        "        convergence_curve.append(alpha_score)\n",
        "\n",
        "        if (t + 1) % 50 == 0 or t == 0:\n",
        "            print(f\"Iteration {t+1}/{max_iter} | Best Fitness: {alpha_score:.6f}\")\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    return alpha, alpha_score, convergence_curve, total_time\n",
        "\n",
        "# ----------------------------------------\n",
        "# Application: Large-scale Nonlinear Optimization\n",
        "# ----------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    dim = 100  # Large scale (100 variables)\n",
        "    bounds = (-5.12, 5.12)\n",
        "    n_wolves = 40\n",
        "    max_iter = 300\n",
        "\n",
        "    best_pos, best_score, convergence, runtime = GWO(rastrigin, dim, bounds, n_wolves, max_iter)\n",
        "\n",
        "    print(\"\\n=== Optimization Complete ===\")\n",
        "    print(f\"Best Fitness Value : {best_score:.8f}\")\n",
        "    print(f\"Runtime            : {runtime:.2f} seconds\")\n",
        "    print(f\"First 10 Dimensions of Best Position:\\n{best_pos[:10]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHhTvdRiEdMo",
        "outputId": "ac6a1af1-28f9-40d0-88af-b41a6460e9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/300 | Best Fitness: 1669.346486\n",
            "Iteration 50/300 | Best Fitness: 448.889405\n",
            "Iteration 100/300 | Best Fitness: 128.559265\n",
            "Iteration 150/300 | Best Fitness: 90.419914\n",
            "Iteration 200/300 | Best Fitness: 53.115557\n",
            "Iteration 250/300 | Best Fitness: 41.973356\n",
            "Iteration 300/300 | Best Fitness: 32.282022\n",
            "\n",
            "=== Optimization Complete ===\n",
            "Best Fitness Value : 32.28202226\n",
            "Runtime            : 1.18 seconds\n",
            "First 10 Dimensions of Best Position:\n",
            "[ 3.30960094e-02 -7.03173443e-02  7.06492378e-03 -5.28895544e-03\n",
            "  9.25004377e-03 -6.02325146e-04 -9.98891317e-01  9.83216378e-03\n",
            "  9.92575390e-01 -2.13900795e-03]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}